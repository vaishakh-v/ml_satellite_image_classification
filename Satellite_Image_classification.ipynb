{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10724697,
          "sourceType": "datasetVersion",
          "datasetId": 6647634
        }
      ],
      "dockerImageVersionId": 30887,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishakh-v/ml_satellite_image_classification/blob/main/Satellite_Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Wq6ELjMRnKbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb94754-b48d-4415-8e2d-4174494bfac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CubeSat"
      ],
      "metadata": {
        "id": "5bZMOGqb6SDG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem statement"
      ],
      "metadata": {
        "id": "ffkzfQKX6SDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The task at hand is to develop a machine learning model that accurately classifies data captured by CubeSats. The goal is to prioritize which images are most valuable for transmission back to Earth, given the limited onboard resources and slow data downlink speeds. The prioritization criteria involved dividing the data into five classes: Priority, Noisy, Blurry, Missing_data, and Corrupt.\n",
        "The project is motivated by a nanosatelite mission, Visible Extra-galactic Background RadiaTion Exploration by CubeSat(VERTECS), a joing venture by the Kyushu institute of technology and collaborators. Due to size and resource constratints, the CubeSat was equiped with a prototype Camera Controller Beard(CCB) which carries a Raspberry Pi module 4 intended to run the machine learning model. The challenge therefore becomes finding the balance between a lightweight, fast inference model (usually simple models) and a high accuracy model(usually more comples and therefore heavier models) for classifying images received by the CubeSat."
      ],
      "metadata": {
        "id": "6QJuGAGY6SDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "More details on the hack4dev hackathon can be ffound through the following github link ` https://github.com/Hack4Dev/CubeSat_ImageClassify `."
      ],
      "metadata": {
        "id": "TSHTd45z6SDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solution techniques/strategies"
      ],
      "metadata": {
        "id": "8TL98jAl6SDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Available tools"
      ],
      "metadata": {
        "id": "8jRkbDHV6SDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Clean data for training, validation and testing\n",
        "2. Prewritten notebooks offering a framework to start from\n",
        "3. A CubeSat CNN already developed with 100% accuracy\n",
        "\n",
        "The problem is to ensure the model has:\n",
        "\n",
        "i) High accuracy\n",
        "\n",
        "ii) Fast inference speed(Low evaluation time)\n",
        "\n",
        "ii) Low algorithm size\n",
        "\n",
        "iii) Minimal strain on cpu(the Raspberry PI on which it is to run is limited 8GB RAM)"
      ],
      "metadata": {
        "id": "gb2Qlef06SDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Heuristics"
      ],
      "metadata": {
        "id": "s1feRiP06SDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Fine tune parameters to increase accuracy of simple models**\n",
        "Applying Occam's razor principle of the simpler model should be the first one to investigate for a solution\n",
        "\n",
        "**2) Reduce size and compute resources demanded by the CNN**\n",
        "The CNN is already 100% accurate. Reducing size and evaluation time would suffice."
      ],
      "metadata": {
        "id": "ew6IhyfZ6SDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the evaluation pipeline"
      ],
      "metadata": {
        "id": "Nqgp6aXt6SDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import psutil\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import gc\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pprint\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "# Function to monitor memory and CPU usage\n",
        "def monitor_resources(mem_usage, cpu_usage, stop_event):\n",
        "    process = psutil.Process(os.getpid())\n",
        "    while not stop_event.is_set():\n",
        "        mem = process.memory_info().rss / (1024 * 1024)  # Memory in MB\n",
        "        cpu = process.cpu_percent(interval=None)  # CPU usage percentage\n",
        "        mem_usage.append(mem)\n",
        "        cpu_usage.append(cpu)\n",
        "        time.sleep(0.1)  # Sampling interval\n",
        "\n",
        "# Function to preprocess test data\n",
        "def preprocess_data(preprocessing_fn, X_test_raw):\n",
        "    return preprocessing_fn(X_test_raw)\n",
        "\n",
        "# Function to make predictions\n",
        "def make_predictions(model, X_test_processed):\n",
        "    return model.predict(X_test_processed)\n",
        "\n",
        "# Function to plot the confusion matrix\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted Labels\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.show()\n",
        "\n",
        "def print_evaluation_results(metrics, class_names):\n",
        "    print(\"\\n### Evaluation Metrics ###\\n\")\n",
        "    print(f\"Evaluation Time:       {metrics['evaluation_time']:.2f} seconds\")\n",
        "    print(f\"Peak Memory Usage:     {metrics['peak_memory_usage']:.2f} MB\")\n",
        "    print(f\"Average CPU Usage:     {metrics['average_cpu_usage']:.2f} %\")\n",
        "    print(f\"Algorithm code size:   {metrics['algorithm_code_size']:.3f} KB\")\n",
        "    print(f\"Accuracy:              {metrics['accuracy']:.3f}\")\n",
        "    print(f\"F1 Score:              {metrics['f1_score']:.3f}\")\n",
        "    print(\"\\n### Confusion Matrix ###\\n\")\n",
        "    plot_confusion_matrix(metrics['confusion_matrix'], class_names)\n",
        "\n",
        "def compute_metrics(y_test, y_pred, class_names):\n",
        "    metrics = {}\n",
        "    if len(y_pred.shape) != 1:\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "        y_test = np.argmax(y_test, axis=1)\n",
        "\n",
        "    metrics['accuracy'] = accuracy_score(y_test, y_pred)\n",
        "    metrics['f1_score'] = f1_score(y_test, y_pred, average='weighted')\n",
        "    metrics['confusion_matrix'] = confusion_matrix(y_test, y_pred)\n",
        "    return metrics\n",
        "\n",
        "def calculate_algorithmCode_size(model, preprocessing_fn):\n",
        "    # Model size handling\n",
        "    if hasattr(model, 'get_model_size'):\n",
        "        model_size = model.get_model_size()  # Already in MB\n",
        "    else:\n",
        "        model_size = len(pickle.dumps(model))/ (1024)  # Convert bytes to KB\n",
        "\n",
        "    # Preprocessing size handling\n",
        "    preprocessing_size = len(pickle.dumps(preprocessing_fn)) / (1024)  # Bytes to KB\n",
        "\n",
        "    return round(model_size + preprocessing_size, 3)\n",
        "\n",
        "def evaluate_pipeline(model, X_test_raw, y_test, preprocessing_fn):\n",
        "    class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
        "\n",
        "    # Resource monitoring setup\n",
        "    p = psutil.Process(os.getpid())\n",
        "    p.cpu_affinity([2])\n",
        "    mem_usage = []\n",
        "    cpu_usage = []\n",
        "    stop_monitoring = threading.Event()\n",
        "    monitor_thread = threading.Thread(target=monitor_resources,\n",
        "                                    args=(mem_usage, cpu_usage, stop_monitoring))\n",
        "    monitor_thread.start()\n",
        "\n",
        "    # Timing and processing\n",
        "    start_time = time.time()\n",
        "    X_test_processed = preprocess_data(preprocessing_fn, X_test_raw)\n",
        "    y_pred = make_predictions(model, X_test_processed)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Cleanup and metrics collection\n",
        "    stop_monitoring.set()\n",
        "    monitor_thread.join()\n",
        "\n",
        "    metrics = {\n",
        "        'evaluation_time': end_time - start_time,\n",
        "        'peak_memory_usage': max(mem_usage),\n",
        "        'average_cpu_usage': np.mean(cpu_usage),\n",
        "        'algorithm_code_size': calculate_algorithmCode_size(model, preprocessing_fn)\n",
        "    }\n",
        "    metrics.update(compute_metrics(y_test, y_pred, class_names))\n",
        "\n",
        "    print_evaluation_results(metrics, class_names)\n",
        "\n",
        "    # Memory cleanup\n",
        "    del X_test_processed, y_pred\n",
        "    gc.collect()\n",
        "\n",
        "    return metrics\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:28:42.53777Z",
          "iopub.execute_input": "2025-04-11T08:28:42.538331Z",
          "iopub.status.idle": "2025-04-11T08:28:44.827819Z",
          "shell.execute_reply.started": "2025-04-11T08:28:42.538287Z",
          "shell.execute_reply": "2025-04-11T08:28:44.827112Z"
        },
        "id": "pt1C1rZH6SDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8168fd5-7752-4da8-9c59-a24bb64ec1e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing stuff"
      ],
      "metadata": {
        "id": "Wu1gLcuQ6SDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle # saving models as a pickle file\n",
        "import gc # garbage collector to free memory"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:28:50.258985Z",
          "iopub.execute_input": "2025-04-11T08:28:50.259497Z",
          "iopub.status.idle": "2025-04-11T08:28:50.263668Z",
          "shell.execute_reply.started": "2025-04-11T08:28:50.259468Z",
          "shell.execute_reply": "2025-04-11T08:28:50.262744Z"
        },
        "id": "uD7Xa_Dk6SDN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBOOST specific imports"
      ],
      "metadata": {
        "id": "pCl-RwDX6SDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:28:50.595425Z",
          "iopub.execute_input": "2025-04-11T08:28:50.595774Z",
          "iopub.status.idle": "2025-04-11T08:28:50.882555Z",
          "shell.execute_reply.started": "2025-04-11T08:28:50.595752Z",
          "shell.execute_reply": "2025-04-11T08:28:50.881822Z"
        },
        "id": "vvn7_xzg6SDN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CNN specific imports"
      ],
      "metadata": {
        "id": "ZY2z17xO6SDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential  # Importing Sequential to build the model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.layers import DepthwiseConv2D, SeparableConv2D\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:28:52.384215Z",
          "iopub.execute_input": "2025-04-11T08:28:52.384716Z",
          "iopub.status.idle": "2025-04-11T08:28:59.151848Z",
          "shell.execute_reply.started": "2025-04-11T08:28:52.384692Z",
          "shell.execute_reply": "2025-04-11T08:28:59.150845Z"
        },
        "id": "n9M8m6BE6SDN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data and visualizing it"
      ],
      "metadata": {
        "id": "dpeyiQgD6SDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the `data` folder, you will find three types of datasets, each saved as numpy files along with their corresponding label files. These datasets are organized as follows:\n",
        "\n",
        "1.\t`train_images.npy`: Contains images used for **training** machine and deep learning models. The associated labels are stored in train_labels.npy.\n",
        "2.\t`val_images.npy`: Contains images used for **validating** the trained models. The corresponding labels are stored in val_labels.npy.\n",
        "3.\t`test_images.npy`: Contains images used for **testing** the trained models. The associated labels are stored in test_labels.npy.\n",
        "\n",
        "Let’s now read and explore these datasets."
      ],
      "metadata": {
        "id": "_ky_ETsE6SDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the datasets\n",
        "train_images = np.load('/content/drive/MyDrive/CubeSat-ML-Optimization-Dataset/test_images1.npy')\n",
        "train_labels = np.load('/kaggle/input/cubesat-ml-optimization-dataeset/train_labels.npy')\n",
        "val_images = np.load('/kaggle/input/cubesat-ml-optimization-dataeset/val_images.npy')\n",
        "val_labels = np.load('/kaggle/input/cubesat-ml-optimization-dataeset/val_labels.npy')\n",
        "test_images = np.load('/kaggle/input/cubesat-ml-optimization-dataeset/test_images1.npy')\n",
        "test_labels = np.load('/kaggle/input/cubesat-ml-optimization-dataeset/test_labels.npy')\n",
        "\n",
        "# Print basic information about each dataset\n",
        "print(f\"Training images: {train_images.shape}, Training labels: {train_labels.shape}\")\n",
        "print(f\"Validation images: {val_images.shape}, Validation labels: {val_labels.shape}\")\n",
        "print(f\"Testing images: {test_images.shape}, Testing labels: {test_labels.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:28:59.153125Z",
          "iopub.execute_input": "2025-04-11T08:28:59.153706Z",
          "iopub.status.idle": "2025-04-11T08:30:02.250623Z",
          "shell.execute_reply.started": "2025-04-11T08:28:59.153681Z",
          "shell.execute_reply": "2025-04-11T08:30:02.249725Z"
        },
        "id": "DcM_rtoG6SDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "d1867815-f5e2-4e65-bc81-c321de6d182e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/cubesat-ml-optimization-dataeset/train_images.npy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0de052053d7a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/cubesat-ml-optimization-dataeset/train_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/cubesat-ml-optimization-dataeset/train_labels.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/cubesat-ml-optimization-dataeset/val_images.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/cubesat-ml-optimization-dataeset/val_labels.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/cubesat-ml-optimization-dataeset/train_images.npy'"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The training dataset consists of 9,711 samples of 512x512 RGB images, while the validation and testing sets each contain 3,237 samples."
      ],
      "metadata": {
        "id": "1VvN4S0w6SDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualising the data"
      ],
      "metadata": {
        "id": "S6P6lMWM6SDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we will be working with contains five classes, described as follows:\n",
        "- **Blurry**: Data captured while the satellite is in motion, resulting in blurred images.\n",
        "- **Corrupt**: Images with defects from improper camera priming or stray light.\n",
        "- **Missing Data**: Images with partial or complete data loss.\n",
        "- **Noisy**: Images over-saturated with noise from radiation or other sources.\n",
        "- **Priority**: Clear images suitable for scientific analysis on the ground."
      ],
      "metadata": {
        "id": "8wnU8THk6SDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Let’s take a look at these datasets."
      ],
      "metadata": {
        "id": "BNrHo1N86SDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class names\n",
        "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
        "\n",
        "# Get the unique labels in the training set\n",
        "unique_labels = np.unique(train_labels)\n",
        "\n",
        "\n",
        "# Display the first 5 images for each class\n",
        "for label in unique_labels:\n",
        "    # Find the indices of images belonging to the current class\n",
        "    class_indices = np.where(train_labels == label)[0]\n",
        "\n",
        "    # Select the first 5 images of this class\n",
        "    num_images_to_display = min(5, len(class_indices))\n",
        "    selected_indices = class_indices[:num_images_to_display]\n",
        "    selected_images = train_images[selected_indices] / 255.0  # Normalize images for better visualization\n",
        "\n",
        "    # Plot the selected images\n",
        "    fig, axes = plt.subplots(1, num_images_to_display, figsize=(20, 4))\n",
        "    fig.suptitle(f'Class: {class_names[label]}', fontsize=16)\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        ax.imshow(selected_images[i])\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "    print()"
      ],
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:02.252426Z",
          "iopub.execute_input": "2025-04-11T08:30:02.252665Z",
          "iopub.status.idle": "2025-04-11T08:30:06.205956Z",
          "shell.execute_reply.started": "2025-04-11T08:30:02.252645Z",
          "shell.execute_reply": "2025-04-11T08:30:06.204965Z"
        },
        "id": "0XqwyHA-6SDP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we were to rank these images in terms of importance based on their significance in capturing and transmitting them back to Earth, the order would be:\n",
        "\n",
        "1.\t`Priority`: Images with the highest importance and usability.\n",
        "2.\t`Noisy` & `Blurry`: Impure images that are potentially recoverable with preprocessing.\n",
        "3.\t`Corrupt` and `Missing Data`: Images with severe issues or missing information, making recovery or reuse least likely.\n",
        "\n",
        "This ranking will help assess model performance by testing its ability to handle different levels of data quality and recover meaningful information from problematic images."
      ],
      "metadata": {
        "id": "Zpyv0M8L6SDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class Balance Check"
      ],
      "metadata": {
        "id": "0HuQTxsu6SDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the classes in each dataset\n",
        "train_class_counts = np.bincount(train_labels)\n",
        "val_class_counts = np.bincount(val_labels)\n",
        "test_class_counts = np.bincount(test_labels)\n",
        "\n",
        "# Display the class distribution with class names\n",
        "print(\"\\nClass distribution:\")\n",
        "print(f\"Training set: {dict(zip(class_names, train_class_counts))}\")\n",
        "print(f\"Validation set: {dict(zip(class_names, val_class_counts))}\")\n",
        "print(f\"Testing set: {dict(zip(class_names, test_class_counts))}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:06.207478Z",
          "iopub.execute_input": "2025-04-11T08:30:06.207795Z",
          "iopub.status.idle": "2025-04-11T08:30:06.215355Z",
          "shell.execute_reply.started": "2025-04-11T08:30:06.207767Z",
          "shell.execute_reply": "2025-04-11T08:30:06.214233Z"
        },
        "id": "M9-wDl_b6SDP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Priority` class has the most data, followed by `Noisy` and `Blurry`, while `Corrupt` has the least, indicating class imbalance."
      ],
      "metadata": {
        "id": "v-8M1VhQ6SDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent classifier"
      ],
      "metadata": {
        "id": "t3DNKA0a6SDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SGD (Stochastic Gradient Descent) model was a model given at the start of the Hack4dev hackathon through this github link `https://github.com/Hack4Dev/CubeSat_ImageClassify/blob/main/3-ML.ipynb`.\n",
        "\n",
        "This model's performance was poor and it was evidently insensible to forcefully try optimizing a linear classiefier to image data.\n",
        "\n",
        "Moreover, the model performed very poorly on the chosen evaluation metrics.\n",
        "\n",
        "We therefore dropped this model. Nonetheless, we deem it of importance to highlight it here."
      ],
      "metadata": {
        "id": "rNTEz1I76SDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBOOST"
      ],
      "metadata": {
        "id": "l2iemTQp6SDP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBOOST was tried, motivated by Occam's razor principle to see if a simple model could be optimized to reach the desired accuracyy. The rationale behind this was that simpler model are more likely to have small algorithm size and exert less strain on the cpu."
      ],
      "metadata": {
        "id": "4TKFLVnx6SDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "95yK9kcc6SDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data was preprocessed using the `memory_safe_preprocessor()` function. The data is preprocessed in batches to minimise strain on the cpu."
      ],
      "metadata": {
        "id": "8xvbb0Th6SDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "BATCH_SIZE = 512  # Process 512 images at a time\n",
        "TARGET_SIZE = (64, 64)  # Reduced from 512*512 to save memory\n",
        "PCA_COMPONENTS = 300"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:09:47.262435Z",
          "iopub.execute_input": "2025-04-11T08:09:47.262692Z",
          "iopub.status.idle": "2025-04-11T08:09:47.277945Z",
          "shell.execute_reply.started": "2025-04-11T08:09:47.262671Z",
          "shell.execute_reply": "2025-04-11T08:09:47.277063Z"
        },
        "id": "ebdSoWs_6SDQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def memory_safe_preprocessor(images, batch_size=BATCH_SIZE):\n",
        "    \"\"\"Process images in batches to avoid memory overload\"\"\"\n",
        "    num_images = images.shape[0]\n",
        "    for i in range(0, num_images, batch_size):\n",
        "        batch = images[i:i+batch_size]\n",
        "\n",
        "        # Process batch\n",
        "        batch_pre = batch.astype('float32') / 255.0\n",
        "        batch_pre = np.array([resize(img, TARGET_SIZE, anti_aliasing=True) for img in batch_pre])\n",
        "        batch_pre = batch_pre.reshape(len(batch_pre), -1)  # Flatten\n",
        "\n",
        "        # Clean up\n",
        "        del batch\n",
        "        gc.collect()\n",
        "        yield batch_pre"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:09:47.278801Z",
          "iopub.execute_input": "2025-04-11T08:09:47.279149Z",
          "iopub.status.idle": "2025-04-11T08:09:47.294187Z",
          "shell.execute_reply.started": "2025-04-11T08:09:47.279107Z",
          "shell.execute_reply": "2025-04-11T08:09:47.293408Z"
        },
        "id": "MlbdCWjR6SDQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Incremental PCA\n",
        "ipca = IncrementalPCA(n_components=PCA_COMPONENTS, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Process training data in batches\n",
        "train_batches = memory_safe_preprocessor(train_images)\n",
        "X_train_pca = []\n",
        "\n",
        "for i, batch in enumerate(train_batches):\n",
        "    if i == 0:\n",
        "        ipca.partial_fit(batch)\n",
        "    X_batch_pca = ipca.transform(batch)\n",
        "    X_train_pca.append(X_batch_pca)\n",
        "    del batch, X_batch_pca\n",
        "    gc.collect()\n",
        "\n",
        "X_train_pca = np.concatenate(X_train_pca)\n",
        "\n",
        "\n",
        "# Process validation data in batches\n",
        "val_batches = memory_safe_preprocessor(val_images)\n",
        "X_val_pca = []\n",
        "\n",
        "for batch in val_batches:\n",
        "    X_batch_pca = ipca.transform(batch)\n",
        "    X_val_pca.append(X_batch_pca)\n",
        "    del batch, X_batch_pca\n",
        "    gc.collect()\n",
        "\n",
        "X_val_pca = np.concatenate(X_val_pca)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:09:47.2959Z",
          "iopub.execute_input": "2025-04-11T08:09:47.296127Z",
          "iopub.status.idle": "2025-04-11T08:16:17.233926Z",
          "shell.execute_reply.started": "2025-04-11T08:09:47.296108Z",
          "shell.execute_reply": "2025-04-11T08:16:17.232979Z"
        },
        "id": "57VbWatU6SDQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture definition"
      ],
      "metadata": {
        "id": "siQpjG1T6SDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle class imbalance through sample weights\n",
        "class_counts = np.bincount(train_labels)\n",
        "class_weights = {i: sum(class_counts)/count for i, count in enumerate(class_counts)}\n",
        "sample_weights = np.array([class_weights[lbl] for lbl in train_labels])\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softmax',  # Explicitly set for multi-class\n",
        "    num_class=5,\n",
        "    n_estimators=250,          # Increase from 150 for increased accuracy\n",
        "    learning_rate=0.05,        # Lower rate, more trees\n",
        "    max_depth=7,               # Deeper trees (from 5)\n",
        "    min_child_weight=3,         # Control overfitting\n",
        "    gamma=0.2,                 # Regularization\n",
        "    subsample=0.9,             # More data per tree\n",
        "    colsample_bytree=0.8,\n",
        "    tree_method='hist',\n",
        "    reg_alpha=0.1,             # L1 regularization\n",
        "    reg_lambda=0.1,            # L2 regularization\n",
        "    eval_metric='mlogloss',    # Better for multi-class\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:16:17.234916Z",
          "iopub.execute_input": "2025-04-11T08:16:17.23524Z",
          "iopub.status.idle": "2025-04-11T08:16:17.243591Z",
          "shell.execute_reply.started": "2025-04-11T08:16:17.235211Z",
          "shell.execute_reply": "2025-04-11T08:16:17.242769Z"
        },
        "id": "llhp1o5U6SDU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "ebJiMCU76SDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train in batches (manual incremental training)\n",
        "batch_size = 2048\n",
        "for i in range(0, len(X_train_pca), batch_size):\n",
        "    xgb_model.fit(\n",
        "        X_train_pca[i:i+batch_size],\n",
        "        train_labels[i:i+batch_size],\n",
        "        sample_weight=sample_weights[i:i+batch_size],\n",
        "        xgb_model=xgb_model if i > 0 else None,  # Continue training\n",
        "        eval_set=[(X_val_pca, val_labels)],\n",
        "        verbose=0\n",
        "    )\n",
        "    print(f\"Processed {min(i+batch_size, len(X_train_pca))}/{len(X_train_pca)} samples\")\n",
        "    gc.collect()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:16:17.24433Z",
          "iopub.execute_input": "2025-04-11T08:16:17.24459Z",
          "iopub.status.idle": "2025-04-11T08:20:50.732283Z",
          "shell.execute_reply.started": "2025-04-11T08:16:17.244569Z",
          "shell.execute_reply": "2025-04-11T08:20:50.731455Z"
        },
        "id": "4VYx8KCG6SDU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation of trained model"
      ],
      "metadata": {
        "id": "c6HjtL4U6SDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate final model\n",
        "val_preds = xgb_model.predict(X_val_pca)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# Save model components\n",
        "import joblib\n",
        "joblib.dump(ipca, 'pca_model.pkl')\n",
        "joblib.dump(xgb_model, 'xgb_model.pkl')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:20:50.734135Z",
          "iopub.execute_input": "2025-04-11T08:20:50.734395Z",
          "iopub.status.idle": "2025-04-11T08:20:51.540781Z",
          "shell.execute_reply.started": "2025-04-11T08:20:50.734371Z",
          "shell.execute_reply": "2025-04-11T08:20:51.540093Z"
        },
        "id": "B1dHVlKB6SDV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieves an accuracy of 67.47% much lower than the benchmarch cnn which had 100% accuracy.\n",
        "\n",
        "Next we evaluate on the model to see how it performs on the chosen metrics...."
      ],
      "metadata": {
        "id": "yj4lYzGb6SDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the xgboost model"
      ],
      "metadata": {
        "id": "HXdzm4Nv6SDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocess Test Data (Same as Training)\n",
        "def preprocess_test(images):\n",
        "    \"\"\"Identical preprocessing to training pipeline\"\"\"\n",
        "    test_batches = memory_safe_preprocessor(images)\n",
        "    processed = []\n",
        "    for batch in test_batches:\n",
        "        # Apply PCA transformation\n",
        "        batch_pca = ipca.transform(batch)\n",
        "        processed.append(batch_pca)\n",
        "        del batch, batch_pca\n",
        "        gc.collect()\n",
        "    return np.concatenate(processed)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:20:51.541482Z",
          "iopub.execute_input": "2025-04-11T08:20:51.541689Z",
          "iopub.status.idle": "2025-04-11T08:20:51.545805Z",
          "shell.execute_reply.started": "2025-04-11T08:20:51.541671Z",
          "shell.execute_reply": "2025-04-11T08:20:51.545088Z"
        },
        "id": "IwrUzXr06SDV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_pipeline(xgb_model, test_images, test_labels, preprocess_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:20:51.5465Z",
          "iopub.execute_input": "2025-04-11T08:20:51.546741Z",
          "iopub.status.idle": "2025-04-11T08:22:30.073707Z",
          "shell.execute_reply.started": "2025-04-11T08:20:51.54672Z",
          "shell.execute_reply": "2025-04-11T08:22:30.072867Z"
        },
        "id": "lbubL85a6SDV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model's evaluation results are too poor whether it is in algorithm size(15MB) to peak memory used (14GB - which by far exceeds our limit of 8GB).\n",
        "\n",
        "The model performs worse than the benchmark."
      ],
      "metadata": {
        "id": "GL2IkRu86SDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Networks"
      ],
      "metadata": {
        "id": "yTYLB43g6SDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "50XPCBEa6SDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_CNN(X):\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:06.216368Z",
          "iopub.execute_input": "2025-04-11T08:30:06.216644Z",
          "iopub.status.idle": "2025-04-11T08:30:06.234332Z",
          "shell.execute_reply.started": "2025-04-11T08:30:06.216621Z",
          "shell.execute_reply": "2025-04-11T08:30:06.233458Z"
        },
        "id": "3i-K-jL06SDV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the labels (assuming you have 5 classes)\n",
        "train_labels = to_categorical(train_labels, num_classes=5)\n",
        "val_labels = to_categorical(val_labels, num_classes=5)\n",
        "test_labels_hot = to_categorical(test_labels, num_classes=5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:06.235141Z",
          "iopub.execute_input": "2025-04-11T08:30:06.235453Z",
          "iopub.status.idle": "2025-04-11T08:30:06.25008Z",
          "shell.execute_reply.started": "2025-04-11T08:30:06.23543Z",
          "shell.execute_reply": "2025-04-11T08:30:06.249346Z"
        },
        "id": "7T5e_RzV6SDW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train CubeCatNet CNN mdoel"
      ],
      "metadata": {
        "id": "tno-GZth6SDW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define and train a Convolutional Neural Network (CNN) model that was defined in the paper https://arxiv.org/pdf/2408.14865"
      ],
      "metadata": {
        "id": "-SZTIurF6SDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(512, 512, 3)),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    Conv2D(32, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    Conv2D(128, (3, 3), activation='relu'),  # Convolutional layer + ReLU activation\n",
        "    MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    GlobalAveragePooling2D(),  # Global average pooling layer\n",
        "    Dense(5, activation='softmax')  # Output layer with 5 neurons (one for each class) + Softmax activation\n",
        "])\n",
        "\n",
        "# Compile the model with appropriate loss function, optimizer, and metrics\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model defined and compiled successfully.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:06.251039Z",
          "iopub.execute_input": "2025-04-11T08:30:06.251371Z",
          "iopub.status.idle": "2025-04-11T08:30:08.671759Z",
          "shell.execute_reply.started": "2025-04-11T08:30:06.251337Z",
          "shell.execute_reply": "2025-04-11T08:30:08.670759Z"
        },
        "id": "EKnOHahR6SDW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:08.674485Z",
          "iopub.execute_input": "2025-04-11T08:30:08.674764Z",
          "iopub.status.idle": "2025-04-11T08:30:08.698379Z",
          "shell.execute_reply.started": "2025-04-11T08:30:08.674741Z",
          "shell.execute_reply": "2025-04-11T08:30:08.697431Z"
        },
        "id": "YyiWD9QH6SDW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model  training"
      ],
      "metadata": {
        "id": "BESKqAZp6SDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=10,  # Number of epochs\n",
        "    batch_size=64,  # Batch size\n",
        ")\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:30:08.700295Z",
          "iopub.execute_input": "2025-04-11T08:30:08.700549Z",
          "iopub.status.idle": "2025-04-11T08:37:31.479549Z",
          "shell.execute_reply.started": "2025-04-11T08:30:08.700527Z",
          "shell.execute_reply": "2025-04-11T08:37:31.478437Z"
        },
        "id": "Acds_0EE6SDW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Saving the CNN model**"
      ],
      "metadata": {
        "id": "bwoP_JO36SDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('cnn_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:31.480913Z",
          "iopub.execute_input": "2025-04-11T08:37:31.481328Z",
          "iopub.status.idle": "2025-04-11T08:37:31.558134Z",
          "shell.execute_reply.started": "2025-04-11T08:37:31.481288Z",
          "shell.execute_reply": "2025-04-11T08:37:31.55747Z"
        },
        "id": "YZKyzi2i6SDX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation set results for CubeSat CNN"
      ],
      "metadata": {
        "id": "oFG2GBZA6SDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opening the pickle file"
      ],
      "metadata": {
        "id": "hKfBAA-L6SDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cnn_model.pkl', 'rb') as file:\n",
        "    cnn_loaded_model = pickle.load(file)\n",
        "\n",
        "val_predictions = cnn_loaded_model.predict(val_images)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:31.558845Z",
          "iopub.execute_input": "2025-04-11T08:37:31.559118Z",
          "iopub.status.idle": "2025-04-11T08:37:45.831319Z",
          "shell.execute_reply.started": "2025-04-11T08:37:31.559095Z",
          "shell.execute_reply": "2025-04-11T08:37:45.830037Z"
        },
        "id": "BNxkvt8h6SDX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure val_labels and val_predictions have the same samples (N)\n",
        "print(\"val_labels shape:\", val_labels.shape)\n",
        "print(\"val_predictions shape:\", val_predictions.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:45.832659Z",
          "iopub.execute_input": "2025-04-11T08:37:45.833049Z",
          "iopub.status.idle": "2025-04-11T08:37:45.839209Z",
          "shell.execute_reply.started": "2025-04-11T08:37:45.832991Z",
          "shell.execute_reply": "2025-04-11T08:37:45.83812Z"
        },
        "id": "ZjgPKX_x6SDX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Convert from one-hot or probability distributions to single integer class indices\n",
        "val_labels = np.argmax(val_labels, axis=1)\n",
        "val_predictions= np.argmax(val_predictions, axis=1)\n",
        "\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels, val_predictions))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:45.840303Z",
          "iopub.execute_input": "2025-04-11T08:37:45.840533Z",
          "iopub.status.idle": "2025-04-11T08:37:45.870257Z",
          "shell.execute_reply.started": "2025-04-11T08:37:45.840512Z",
          "shell.execute_reply": "2025-04-11T08:37:45.869408Z"
        },
        "id": "UOHI6RMb6SDX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define class names\n",
        "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_predictions)\n",
        "\n",
        "# Plot the confusion matrix with class names\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "# Customize and display the plot\n",
        "fig, ax = plt.subplots(figsize=(8, 8))  # Set the figure size\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')  # Use a blue colormap\n",
        "plt.title(\"Confusion Matrix with Class Names\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:45.871268Z",
          "iopub.execute_input": "2025-04-11T08:37:45.871572Z",
          "iopub.status.idle": "2025-04-11T08:37:46.357108Z",
          "shell.execute_reply.started": "2025-04-11T08:37:45.871541Z",
          "shell.execute_reply": "2025-04-11T08:37:46.356341Z"
        },
        "id": "0HQxsEzv6SDX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluating the model"
      ],
      "metadata": {
        "id": "nc5mVyg56SDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_pipeline(cnn_loaded_model, test_images, test_labels_hot, preprocessing_CNN)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:46.357818Z",
          "iopub.execute_input": "2025-04-11T08:37:46.358068Z",
          "iopub.status.idle": "2025-04-11T08:37:58.122062Z",
          "shell.execute_reply.started": "2025-04-11T08:37:46.358047Z",
          "shell.execute_reply": "2025-04-11T08:37:58.121301Z"
        },
        "id": "mdbNvxgk6SDY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the benchmark CNN model that is to be optimized."
      ],
      "metadata": {
        "id": "T8xT-eH46SDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing separable convo layers on the CubeSat CNN to reduce size"
      ],
      "metadata": {
        "id": "qOCUOIYX6SDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We use separable convo layers which reduce parameters by ~90% compared to the standard convolutions\n",
        "2. We also use a depthwise+pointwise block motivated by the mobileNets architecture"
      ],
      "metadata": {
        "id": "QqE8vHWr6SDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_compact_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        SeparableConv2D(16, (3,3), activation='relu', input_shape=(512,512,3)),\n",
        "        MaxPooling2D(2,2),\n",
        "        SeparableConv2D(32, (3,3), activation='relu'),\n",
        "        MaxPooling2D(2,2),\n",
        "        DepthwiseConv2D((3,3), activation='relu'),\n",
        "        Conv2D(64, (1,1), activation='relu'),\n",
        "        GlobalAveragePooling2D(),# Compile the model with appropriate loss function, optimizer, and metric\n",
        "        Dense(5, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compare model sizes\n",
        "#original_model = model  # Your existing model\n",
        "compact_model = create_compact_model()\n",
        "compact_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model defined and compiled successfully.\")\n",
        "\n",
        "#print(f\"Original Params: {original_model.count_params()/1e6:.1f}M\")\n",
        "print(f\"Compact Params: {compact_model.count_params()/1e6:.1f}M\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:58.122848Z",
          "iopub.execute_input": "2025-04-11T08:37:58.123145Z",
          "iopub.status.idle": "2025-04-11T08:37:58.183431Z",
          "shell.execute_reply.started": "2025-04-11T08:37:58.123123Z",
          "shell.execute_reply": "2025-04-11T08:37:58.182755Z"
        },
        "id": "o8ZbJqLo6SDZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "compact_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:58.184122Z",
          "iopub.execute_input": "2025-04-11T08:37:58.184356Z",
          "iopub.status.idle": "2025-04-11T08:37:58.201858Z",
          "shell.execute_reply.started": "2025-04-11T08:37:58.184335Z",
          "shell.execute_reply": "2025-04-11T08:37:58.200948Z"
        },
        "id": "i9yCy0tC6SDa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`It is noteworthy that the params here have been reduced to 3,536 from 98,085 in the benchmark.`"
      ],
      "metadata": {
        "id": "W6Hxlh5e6SDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data\n",
        "history = compact_model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=10,  # Number of epochs\n",
        "    batch_size=64,  # Batch size\n",
        ")\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:37:58.202682Z",
          "iopub.execute_input": "2025-04-11T08:37:58.202959Z",
          "iopub.status.idle": "2025-04-11T08:45:11.207223Z",
          "shell.execute_reply.started": "2025-04-11T08:37:58.202929Z",
          "shell.execute_reply": "2025-04-11T08:45:11.206337Z"
        },
        "id": "84QeUr3o6SDa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### saving the model"
      ],
      "metadata": {
        "id": "KfooR-wD6SDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('cnn_model2.pkl', 'wb') as file:\n",
        "    pickle.dump(compact_model, file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:45:11.208184Z",
          "iopub.execute_input": "2025-04-11T08:45:11.208487Z",
          "iopub.status.idle": "2025-04-11T08:45:11.252219Z",
          "shell.execute_reply.started": "2025-04-11T08:45:11.208452Z",
          "shell.execute_reply": "2025-04-11T08:45:11.251411Z"
        },
        "id": "7epoH2_t6SDa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation set results using the separable convo2D"
      ],
      "metadata": {
        "id": "MN2rEiBL6SDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cnn_model2.pkl', 'rb') as file:\n",
        "    cnn_loaded_model2 = pickle.load(file)\n",
        "\n",
        "val_predictions = cnn_loaded_model2.predict(val_images)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:45:11.253079Z",
          "iopub.execute_input": "2025-04-11T08:45:11.253336Z",
          "iopub.status.idle": "2025-04-11T08:45:30.493166Z",
          "shell.execute_reply.started": "2025-04-11T08:45:11.253315Z",
          "shell.execute_reply": "2025-04-11T08:45:30.492419Z"
        },
        "id": "KEFr_Xit6SDa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A lesson learned the hard way\n",
        "1. Ensure val_labels and val_predictions have the same samples (N)\n",
        "2. Verify whether or not they are one hot encoded to decide whether to do np.argmax.\n",
        "3. Do np.argmax if and only if the shapes are 2D arrays. Keep in mind the np.argmax was done when evaluating the previous model. Reruning that line of code will intefere with data in the variable.\n"
      ],
      "metadata": {
        "id": "7c3-QNLO6SDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"val_labels shape:\", val_labels.shape)\n",
        "print(\"val_predictions shape:\", val_predictions.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T08:45:30.494186Z",
          "iopub.execute_input": "2025-04-11T08:45:30.494435Z",
          "iopub.status.idle": "2025-04-11T08:45:30.49948Z",
          "shell.execute_reply.started": "2025-04-11T08:45:30.494413Z",
          "shell.execute_reply": "2025-04-11T08:45:30.498552Z"
        },
        "id": "bjHa1lWq6SDb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Convert from one-hot or probability distributions to single integer class indices\n",
        "val_predictions = np.argmax(val_predictions, axis=1)\n",
        "#val_labels = np.argmax(val_labels, axis=1)\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels, val_predictions))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:07:57.871755Z",
          "iopub.execute_input": "2025-04-11T09:07:57.872214Z",
          "iopub.status.idle": "2025-04-11T09:07:57.885399Z",
          "shell.execute_reply.started": "2025-04-11T09:07:57.87218Z",
          "shell.execute_reply": "2025-04-11T09:07:57.884665Z"
        },
        "id": "CORTCgrt6SDb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define class names\n",
        "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_predictions)\n",
        "\n",
        "# Plot the confusion matrix with class names\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "# Customize and display the plot\n",
        "fig, ax = plt.subplots(figsize=(8, 8))  # Set the figure size\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')  # Use a blue colormap\n",
        "plt.title(\"Confusion Matrix with Class Names\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:07:59.906248Z",
          "iopub.execute_input": "2025-04-11T09:07:59.906568Z",
          "iopub.status.idle": "2025-04-11T09:08:00.148728Z",
          "shell.execute_reply.started": "2025-04-11T09:07:59.906542Z",
          "shell.execute_reply": "2025-04-11T09:08:00.147802Z"
        },
        "id": "MP_0VaCu6SDb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate on the compact_model"
      ],
      "metadata": {
        "id": "e8ASp_Bz6SDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_pipeline(compact_model, test_images, test_labels_hot, preprocessing_CNN)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:08:02.868807Z",
          "iopub.execute_input": "2025-04-11T09:08:02.869215Z",
          "iopub.status.idle": "2025-04-11T09:08:12.422251Z",
          "shell.execute_reply.started": "2025-04-11T09:08:02.86917Z",
          "shell.execute_reply": "2025-04-11T09:08:12.421123Z"
        },
        "id": "cESqqtrY6SDc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only caveat in this model's performance is the memory usage. Next we will try to reduce the peak memory used to under 8GB."
      ],
      "metadata": {
        "id": "fpaOGEEs6SDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Taking a gamble: trading accuracy for size and speed."
      ],
      "metadata": {
        "id": "C2gsbeQ86SDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We drastically simplify the CNN to make it as light as possible.\n",
        "\n",
        "The image sizes have also been reduced from (512*512) to (64 * 64). It is noteworthy to mention that the model accuracy is not interfered with in too much a way.\n",
        "\n",
        "A challenge in laying out this architecture lay in tweaking the kernels, the number of separable convo layers and the degree of pooling."
      ],
      "metadata": {
        "id": "vnxBmjqS6SDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the BEASHT-Net architecture\n",
        "def compacter_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        # Reduced filters + smaller kernel\n",
        "        SeparableConv2D(8, (2,2), activation='relu', input_shape=(64,64,3)),\n",
        "\n",
        "        MaxPooling2D(2,2),\n",
        "\n",
        "        # Simplified block\n",
        "        SeparableConv2D(8, (2,2), activation='relu'),\n",
        "        #MaxPooling2D(2,2),\n",
        "\n",
        "        # Removed depthwise layer (redundant computation)\n",
        "        # Direct to final conv\n",
        "        #Conv2D(16, (1,1), activation='relu'),\n",
        "\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(5, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:08:20.653154Z",
          "iopub.execute_input": "2025-04-11T09:08:20.653497Z",
          "iopub.status.idle": "2025-04-11T09:08:20.658127Z",
          "shell.execute_reply.started": "2025-04-11T09:08:20.65347Z",
          "shell.execute_reply": "2025-04-11T09:08:20.657216Z"
        },
        "id": "CC3WUVYt6SDc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`The commented layers in the architecture above was reached after the realization that with sufficient training, we could do without them. Furthermore, commenting them reduces drastically the model parameters and consequently, the model size from 40KB to 26KB and cpu usage from 6900MB to 6400MB.`\n",
        "\n",
        "`The caveat here is that the model has to be trained for much longer. Moving from the previous separable_convo cnn, we had to train for 150 epochs for comparable performance. For this modified BEASHT_Net architecture, training will be done for 400 epochs.`"
      ],
      "metadata": {
        "id": "8xEbuhuu6SDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "malice_model = compacter_model()\n",
        "malice_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(\"Model defined and compiled successfully.\")\n",
        "\n",
        "#print(f\"Original Params: {original_model.count_params()/1e6:.1f}M\")\n",
        "print(f\"Compact Params: {malice_model.count_params()/1e6:.1f}M\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:08:23.966405Z",
          "iopub.execute_input": "2025-04-11T09:08:23.966733Z",
          "iopub.status.idle": "2025-04-11T09:08:24.011772Z",
          "shell.execute_reply.started": "2025-04-11T09:08:23.966704Z",
          "shell.execute_reply": "2025-04-11T09:08:24.010823Z"
        },
        "id": "ExDDPj316SDd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "malice_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:08:26.221972Z",
          "iopub.execute_input": "2025-04-11T09:08:26.222374Z",
          "iopub.status.idle": "2025-04-11T09:08:26.240311Z",
          "shell.execute_reply.started": "2025-04-11T09:08:26.222342Z",
          "shell.execute_reply": "2025-04-11T09:08:26.239553Z"
        },
        "id": "JRMbxFuT6SDd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`It is noteworthy that the params here have been reduced to 193 from the compact_model's 3,536 and from the 98,085 params in the benchmark.`"
      ],
      "metadata": {
        "id": "NTYyJEvA6SDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`The prev model` - After a few experiments with the model always converging at 98.97% accuracy, a decision to \"overtrain\" the model was reached. To push the number of epoch to 150 and study how that affects the model.\n",
        "`Modified architecture` - we will instead train for 400 epochs rather than 150...training overdriveee..."
      ],
      "metadata": {
        "id": "9xy3VvU-6SDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize images to 128x128 (if originally 512x512)\n",
        "train_images = tf.image.resize(train_images, [64, 64]).numpy()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:08:29.37847Z",
          "iopub.execute_input": "2025-04-11T09:08:29.378769Z",
          "iopub.status.idle": "2025-04-11T09:08:50.057613Z",
          "shell.execute_reply.started": "2025-04-11T09:08:29.378745Z",
          "shell.execute_reply": "2025-04-11T09:08:50.05671Z"
        },
        "id": "6FCoUK146SDd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have validation/test data:\n",
        "val_images = tf.image.resize(val_images, [64, 64]).numpy()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:08:50.061173Z",
          "iopub.execute_input": "2025-04-11T09:08:50.061416Z",
          "iopub.status.idle": "2025-04-11T09:08:56.719058Z",
          "shell.execute_reply.started": "2025-04-11T09:08:50.061393Z",
          "shell.execute_reply": "2025-04-11T09:08:56.71793Z"
        },
        "id": "ytgCMfcs6SDd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Then train with:\n",
        "history = malice_model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=400, # increase to 1000 from 400 ....why?? why not ha ha?? maybe it will increase accuracy from 99.5 to 99.99 lol ha ha ha\n",
        "    batch_size=64,\n",
        "    #validation_data=(val_images, val_labels)  # If using validation\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:11:28.291376Z",
          "iopub.execute_input": "2025-04-11T09:11:28.291755Z",
          "iopub.status.idle": "2025-04-11T09:15:18.816125Z",
          "shell.execute_reply.started": "2025-04-11T09:11:28.291729Z",
          "shell.execute_reply": "2025-04-11T09:15:18.815278Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "m_hbkt-i6SDd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create subplots\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], color='orange', label='Training Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_progress.png')  # Save to file\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:15:18.817588Z",
          "iopub.execute_input": "2025-04-11T09:15:18.817842Z",
          "iopub.status.idle": "2025-04-11T09:15:19.4829Z",
          "shell.execute_reply.started": "2025-04-11T09:15:18.817819Z",
          "shell.execute_reply": "2025-04-11T09:15:19.482263Z"
        },
        "id": "ZNCOc3ur6SDd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Saving the model"
      ],
      "metadata": {
        "id": "lq23trAX6SDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('malice.pkl', 'wb') as file:\n",
        "    pickle.dump(malice_model, file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:18.700498Z",
          "iopub.execute_input": "2025-04-11T09:26:18.700878Z",
          "iopub.status.idle": "2025-04-11T09:26:18.741255Z",
          "shell.execute_reply.started": "2025-04-11T09:26:18.700851Z",
          "shell.execute_reply": "2025-04-11T09:26:18.740564Z"
        },
        "id": "Mdz6YpWt6SDe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Validation set results for the malice model"
      ],
      "metadata": {
        "id": "iA5iWDil6SDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('malice.pkl', 'rb') as file:\n",
        "    malice_model = pickle.load(file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:20.049037Z",
          "iopub.execute_input": "2025-04-11T09:26:20.049331Z",
          "iopub.status.idle": "2025-04-11T09:26:20.152766Z",
          "shell.execute_reply.started": "2025-04-11T09:26:20.049308Z",
          "shell.execute_reply": "2025-04-11T09:26:20.151852Z"
        },
        "id": "iMZJ3iDZ6SDh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_predictions = malice_model.predict(val_images)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:21.983596Z",
          "iopub.execute_input": "2025-04-11T09:26:21.983905Z",
          "iopub.status.idle": "2025-04-11T09:26:23.549439Z",
          "shell.execute_reply.started": "2025-04-11T09:26:21.983875Z",
          "shell.execute_reply": "2025-04-11T09:26:23.548494Z"
        },
        "id": "n32Gi5AO6SDi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"val_labels shape:\", val_labels.shape)\n",
        "print(\"val_predictions shape:\", val_predictions.shape)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:25.742472Z",
          "iopub.execute_input": "2025-04-11T09:26:25.742923Z",
          "iopub.status.idle": "2025-04-11T09:26:25.749472Z",
          "shell.execute_reply.started": "2025-04-11T09:26:25.742875Z",
          "shell.execute_reply": "2025-04-11T09:26:25.748376Z"
        },
        "id": "qeLS378c6SDi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Convert from one-hot or probability distributions to single integer class indices\n",
        "val_pred_classes = np.argmax(val_predictions, axis=-1)\n",
        "#val_labels = np.argmax(val_labels, axis=1)\n",
        "\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels, val_pred_classes))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:28.025586Z",
          "iopub.execute_input": "2025-04-11T09:26:28.025951Z",
          "iopub.status.idle": "2025-04-11T09:26:28.040178Z",
          "shell.execute_reply.started": "2025-04-11T09:26:28.025915Z",
          "shell.execute_reply": "2025-04-11T09:26:28.039296Z"
        },
        "id": "z4aPpQO06SDi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define class names\n",
        "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix with class names\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "# Customize and display the plot\n",
        "fig, ax = plt.subplots(figsize=(8, 8))  # Set the figure size\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')  # Use a blue colormap\n",
        "plt.title(\"Confusion Matrix with Class Names\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:30.391334Z",
          "iopub.execute_input": "2025-04-11T09:26:30.391623Z",
          "iopub.status.idle": "2025-04-11T09:26:30.640685Z",
          "shell.execute_reply.started": "2025-04-11T09:26:30.391598Z",
          "shell.execute_reply": "2025-04-11T09:26:30.640017Z"
        },
        "id": "RvVxfG1p6SDi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on the malice model"
      ],
      "metadata": {
        "id": "5b7uIoYu6SDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_red = tf.image.resize(test_images, [64,64]).numpy()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:33.155477Z",
          "iopub.execute_input": "2025-04-11T09:26:33.155778Z",
          "iopub.status.idle": "2025-04-11T09:26:39.902541Z",
          "shell.execute_reply.started": "2025-04-11T09:26:33.155754Z",
          "shell.execute_reply": "2025-04-11T09:26:39.901758Z"
        },
        "id": "Gsz84AT36SDj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_pipeline(malice_model, test_images_red, test_labels_hot, preprocessing_CNN)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:39.903784Z",
          "iopub.execute_input": "2025-04-11T09:26:39.904135Z",
          "iopub.status.idle": "2025-04-11T09:26:41.211788Z",
          "shell.execute_reply.started": "2025-04-11T09:26:39.904104Z",
          "shell.execute_reply": "2025-04-11T09:26:41.210917Z"
        },
        "id": "aXCLGxru6SDj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quantizing the malice model using tensorflow lite"
      ],
      "metadata": {
        "id": "Ww2bMDVU6SDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def quantize_model(keras_model, save_path='quantized_model.tflite'):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    tflite_model = converter.convert()\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "quantize_model(malice_model) #run once to quantize"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:47.109279Z",
          "iopub.execute_input": "2025-04-11T09:26:47.109592Z",
          "iopub.status.idle": "2025-04-11T09:26:47.827526Z",
          "shell.execute_reply.started": "2025-04-11T09:26:47.109571Z",
          "shell.execute_reply": "2025-04-11T09:26:47.826553Z"
        },
        "id": "Rv-Jr9i-6SDj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparation for evaluation"
      ],
      "metadata": {
        "id": "dbDp1Hk66SDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below QuantizeWrapper is a helper class used to package the tflite model(quantized model) in order for evaluation in the provided pipeline. The provided pipeline does pickling(takes models as pickle files) which is not native form of tflite. More specifically, the quantize wrapper creates a TensorFlow Lite XNNPACK delegate for CPU whose size we can determine by the get_model_size method in the wrapper calss.."
      ],
      "metadata": {
        "id": "SUB55cVW6SDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantizedWrapper:\n",
        "    def __init__(self, tflite_path):\n",
        "        self.tflite_path = tflite_path\n",
        "        self.interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "        self.interpreter.allocate_tensors()\n",
        "        self.input_index = self.interpreter.get_input_details()[0]['index']\n",
        "        self.output_index = self.interpreter.get_output_details()[0]['index']\n",
        "\n",
        "    def predict(self, X):\n",
        "        outputs = []\n",
        "        for x in X:\n",
        "            x = x.astype('float32')\n",
        "            self.interpreter.set_tensor(self.input_index, [x])\n",
        "            self.interpreter.invoke()\n",
        "            outputs.append(self.interpreter.get_tensor(self.output_index)[0])\n",
        "        return np.array(outputs)\n",
        "\n",
        "    def get_model_size(self):\n",
        "        \"\"\"Returns size in MB with verification\"\"\"\n",
        "        if not os.path.exists(self.tflite_path):\n",
        "            return 0.0\n",
        "        bytes_size = os.path.getsize(self.tflite_path)\n",
        "        return round(bytes_size / (1024), 4)  # KB with 4 decimals\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        del state['interpreter']\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        self.__dict__.update(state)\n",
        "        self.interpreter = tf.lite.Interpreter(model_path=self.tflite_path)\n",
        "        self.interpreter.allocate_tensors()\n",
        "        self.input_index = self.interpreter.get_input_details()[0]['index']\n",
        "        self.output_index = self.interpreter.get_output_details()[0]['index']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:56.834294Z",
          "iopub.execute_input": "2025-04-11T09:26:56.834623Z",
          "iopub.status.idle": "2025-04-11T09:26:56.849434Z",
          "shell.execute_reply.started": "2025-04-11T09:26:56.8346Z",
          "shell.execute_reply": "2025-04-11T09:26:56.84865Z"
        },
        "id": "H732c2wH6SDj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# In evaluation pipeline:\n",
        "q_model = QuantizedWrapper('quantized_model.tflite')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:26:59.366293Z",
          "iopub.execute_input": "2025-04-11T09:26:59.366599Z",
          "iopub.status.idle": "2025-04-11T09:26:59.403872Z",
          "shell.execute_reply.started": "2025-04-11T09:26:59.366574Z",
          "shell.execute_reply": "2025-04-11T09:26:59.402963Z"
        },
        "id": "q22PIPED6SDj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation on the quantized model"
      ],
      "metadata": {
        "id": "x0xu2P8r6SDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_predictions = q_model.predict(val_images)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:27:00.774029Z",
          "iopub.execute_input": "2025-04-11T09:27:00.774374Z",
          "iopub.status.idle": "2025-04-11T09:27:01.053337Z",
          "shell.execute_reply.started": "2025-04-11T09:27:00.774345Z",
          "shell.execute_reply": "2025-04-11T09:27:01.052427Z"
        },
        "id": "qAT02GOD6SDk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Convert from one-hot or probability distributions to single integer class indices\n",
        "val_pred_classes = np.argmax(val_predictions, axis=-1)\n",
        "#val_labels = np.argmax(val_labels, axis=1)\n",
        "\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_labels, val_pred_classes))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:27:03.073798Z",
          "iopub.execute_input": "2025-04-11T09:27:03.074132Z",
          "iopub.status.idle": "2025-04-11T09:27:03.087347Z",
          "shell.execute_reply.started": "2025-04-11T09:27:03.074105Z",
          "shell.execute_reply": "2025-04-11T09:27:03.086557Z"
        },
        "id": "xkN582tq6SDk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Define class names\n",
        "class_names = [\"Blurry\", \"Corrupt\", \"Missing_Data\", \"Noisy\", \"Priority\"]\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(val_labels, val_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix with class names\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "# Customize and display the plot\n",
        "fig, ax = plt.subplots(figsize=(8, 8))  # Set the figure size\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')  # Use a blue colormap\n",
        "plt.title(\"Confusion Matrix with Class Names\")\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:27:05.591925Z",
          "iopub.execute_input": "2025-04-11T09:27:05.592295Z",
          "iopub.status.idle": "2025-04-11T09:27:05.873937Z",
          "shell.execute_reply.started": "2025-04-11T09:27:05.592266Z",
          "shell.execute_reply": "2025-04-11T09:27:05.873096Z"
        },
        "id": "kLiwk5bs6SDk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can verify above that performance is exactly like the initial malice_model that was quantized."
      ],
      "metadata": {
        "id": "V334db_O6SDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_pipeline(q_model, test_images_red, test_labels_hot, preprocessing_CNN)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:27:10.632162Z",
          "iopub.execute_input": "2025-04-11T09:27:10.632489Z",
          "iopub.status.idle": "2025-04-11T09:27:11.436764Z",
          "shell.execute_reply.started": "2025-04-11T09:27:10.632464Z",
          "shell.execute_reply": "2025-04-11T09:27:11.435698Z"
        },
        "id": "y8Ku6_hI6SDk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "___"
      ],
      "metadata": {
        "id": "nFK_O7tt6SDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation was done in the notebook delegated by the hackathon organizers"
      ],
      "metadata": {
        "id": "xz_fc2gN6SDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **⚠️ Freeing up Space**"
      ],
      "metadata": {
        "id": "l9VNflcN6SDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Since we will no longer need the original training data (train_images), we can remove it from memory\n",
        "del val_predictions, val_labels, val_images\n",
        "\n",
        "# Force garbage collection to free up memory\n",
        "gc.collect()\n",
        "\n",
        "%reset -f\n",
        "print(\"Data removed from memory.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-11T09:27:56.305552Z",
          "iopub.execute_input": "2025-04-11T09:27:56.305945Z",
          "iopub.status.idle": "2025-04-11T09:27:57.085366Z",
          "shell.execute_reply.started": "2025-04-11T09:27:56.30591Z",
          "shell.execute_reply": "2025-04-11T09:27:57.084399Z"
        },
        "id": "mrgxddSM6SDl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "tjH0cx-r6SDl"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}